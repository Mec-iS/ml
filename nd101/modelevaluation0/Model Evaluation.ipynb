{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model evaluation and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* How to create a test set for your models.\n",
    "* How to use confusion matrices to evaluate false positives, and false negatives.\n",
    "* How to measure accuracy and other model metrics.\n",
    "* How to evaluate regression.\n",
    "* How to detect whether you are overfitting or underfitting based on the complexity of your model.\n",
    "* How to use cross validation to ensure your model is generalizable.\n",
    "\n",
    "With Regression and Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Regression** is a definition of a model that predicts a value.\n",
    "\n",
    "**Classification** is meant to determine a state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To test the validity of a model we check the difference between the outcome of the model and a test dataset that has been previously detached from the total dataset.\n",
    "\n",
    "*You shall never use testing data for training.*\n",
    "\n",
    "Example for model evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size = 0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## How good is the model? Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Classification\n",
    "\n",
    "#### Confusion matrix\n",
    "\\begin{matrix}\n",
    "  relevation/modeled & True & False \\\\\n",
    "  True & True-Positive & False-Negative \\\\\n",
    "  False & False-Positive & False-Negative\n",
    "\\end{matrix}\n",
    " \n",
    "#### Practical example\n",
    "##### Matrix\n",
    "\n",
    "\\begin{matrix}\n",
    "  relevation/modeled & True & False \\\\\n",
    "  True & 1000 & 200 \\\\\n",
    "  False & 800 & 8000\n",
    " \\end{matrix}\n",
    " \n",
    "##### Accuracy\n",
    " $$  accuracy = \\frac{total-of-correctly-modeled}{total-of-observation} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true, y_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Regression\n",
    "\n",
    "**mean absolute error:** addition of absolute values of distances of the points to the linear model (non-differentiable)\n",
    "```\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "classifier = LinearRegression()\n",
    "classifier.fit(X, y)\n",
    "\n",
    "guesses = classifier.predict(X)\n",
    "\n",
    "error = mean_absolute_error(y, guesses)\n",
    "```\n",
    "**mean squared error:** addition of the squared distances\n",
    "```\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "classifier = LinearRegression()\n",
    "classifier.fit(X, y)\n",
    "\n",
    "guesses = classifier.predict(X)\n",
    "\n",
    "error = mean_squared_error(y, guesses)\n",
    "```\n",
    "**R2 score:** one minus the division between the addition of the squared distances of all points and the addition of the distance of the points from the average of all points:\n",
    "$$R2 = 1 - \\frac{mean_squared_error}{mean_absolute_error_from_the_average}$$\n",
    "\n",
    "For a BAD model, $R2$ is close to $0$.\n",
    "\n",
    "For a GOOD model $R2$ is close to $1$.\n",
    "\n",
    "```\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_true = [1, 2, 4]\n",
    "y_pred = [1.3, 2.5, 3.7]\n",
    "\n",
    "r2_score(y_true, y_pred)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model complexity graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given model and dataset, it measures the possible underfitting or overfitting of a given model based on its complexity (linear, quadratic, cubic, etc. regression model on the x-axis) by measuring the *training errors* and the *cross-validation errors* of each model (a couple of numbers on the y-axis):\n",
    "\n",
    "```\n",
    "linear     |  (3, 2) -> underfitting (high-bias error)\n",
    "quadratic  |  (1, 1) -> fitting the dataset\n",
    "cubic      |  (1, 3) -> overfitting (high variance error)\n",
    "degree 4   |  (0, 5) -> overfitting (high variance error)\n",
    "```\n",
    "\n",
    "Quadratic is the choice for this dataset. To perform this kind of choice we use a **cross-validation**. So we are now splitting our dataset into a training set, a cross-validation set and a testing set (to avoid using the testing set before it's really needed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold cross-validation\n",
    "\n",
    "To avoid wasting data, it is possible to have different cycles of computation with different sets of training and testing and cross-validation data coming from the same dataset. The dataset is split in buckets and the training and testing sets are shuffled and the mean is extracted to avoid overfitting or underfitting.\n",
    "\n",
    "```\n",
    "es)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2] [1]\n",
      "[0 1] [2]\n",
      "[1 2] [0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "kf = KFold(3, shuffle=True)\n",
    "for train_indices, test_indices in kf.split(np.array([[1,2,3], [1,2,3], [3,4,5]])):\n",
    "    print(train_indices, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
